{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "16db9e81-fe38-44f0-8a4f-3dba9eba0409",
    "_uuid": "d0469858bd9b00ece464f6267cfad7dc450d5d54"
   },
   "source": [
    "## INTRODUCTION\n",
    "- Itâ€™s a Python based scientific computing package targeted at two sets of audiences:\n",
    "    - A replacement for NumPy to use the power of GPUs\n",
    "    - Deep learning research platform that provides maximum flexibility and speed\n",
    "- pros: \n",
    "    - Iinteractively debugging PyTorch. Many users who have used both frameworks would argue that makes pytorch significantly easier to debug and visualize.\n",
    "    - Clean support for dynamic graphs\n",
    "    - Organizational backing from Facebook\n",
    "    - Blend of high level and low level APIs\n",
    "- cons:\n",
    "    - Much less mature than alternatives\n",
    "    - Limited references / resources outside of the official documentation\n",
    "- I accept you know neural network basics. If you do not know check my tutorial. Because I will not explain neural network concepts detailed, I only explain how to use pytorch for neural network\n",
    "- The most important parts of this tutorial from matrices to ANN. If you learn these parts very well, implementing remaining parts like CNN or RNN will be very easy. \n",
    "<br>\n",
    "<br>**Content:**\n",
    "1. Basics of Pytorch, Linear Regression, Logistic Regression, Artificial Neural Network (ANN), Concolutional Neural Network (CNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "### Recurrent Neural Network (RNN)\n",
    "- RNN is essentially repeating ANN but information get pass through from previous non-linear activation function output.\n",
    "- **Steps of RNN:**\n",
    "    1. Import Libraries\n",
    "    1. Prepare Dataset\n",
    "    1. Create RNN Model\n",
    "        - hidden layer dimension is 100\n",
    "        - number of hidden layer is 1 \n",
    "    1. Instantiate Model\n",
    "    1. Instantiate Loss\n",
    "        - Cross entropy loss\n",
    "        - It also has softmax(logistic function) in it.\n",
    "    1. Instantiate Optimizer\n",
    "        - SGD Optimizer\n",
    "    1. Traning the Model\n",
    "    1. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'test.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "482946c2-72d8-4489-a094-d6cb8993a912",
    "_uuid": "ceffbb7fe5381f0d2f5f234ea37d1f834843edee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "55dd8ffd-6011-49a3-a1fe-c6933c4187b7",
    "_uuid": "840f7b1c60d1a2d5b2222a7c53b2b9d08aac9169"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4359bce668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "# load data\n",
    "train = pd.read_csv(r\"../input/train.csv\",dtype = np.float32)\n",
    "\n",
    "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
    "\n",
    "# train test split. Size of train data is 80% and size of test data is 20%. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "7fbe419e-7ce2-4d72-bb31-8b27e8161f1b",
    "_uuid": "bb1b6d4fb5504400ed7678d8e95d0a4478b5f409",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create RNN\n",
    "input_dim = 28    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "32786a5c-0388-412d-b6da-ee5ace604eda",
    "_uuid": "9c935ac4a1d1964b85513da422ebf60085dca0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.4726558923721313  Accuracy: 42.726190476190474 %\n",
      "Iteration: 1000  Loss: 0.7108388543128967  Accuracy: 71.73809523809524 %\n",
      "Iteration: 1500  Loss: 0.43755194544792175  Accuracy: 85.22619047619048 %\n",
      "Iteration: 2000  Loss: 0.271086722612381  Accuracy: 90.25 %\n",
      "Iteration: 2500  Loss: 0.2235582023859024  Accuracy: 89.5 %\n",
      "Iteration: 3000  Loss: 0.09727417677640915  Accuracy: 92.66666666666667 %\n",
      "Iteration: 3500  Loss: 0.42934906482696533  Accuracy: 92.6547619047619 %\n",
      "Iteration: 4000  Loss: 0.09869173169136047  Accuracy: 94.19047619047619 %\n",
      "Iteration: 4500  Loss: 0.2372802197933197  Accuracy: 95.20238095238095 %\n",
      "Iteration: 5000  Loss: 0.10717732459306717  Accuracy: 95.19047619047619 %\n",
      "Iteration: 5500  Loss: 0.23859672248363495  Accuracy: 94.69047619047619 %\n",
      "Iteration: 6000  Loss: 0.15453924238681793  Accuracy: 96.05952380952381 %\n",
      "Iteration: 6500  Loss: 0.07914035022258759  Accuracy: 95.97619047619048 %\n",
      "Iteration: 7000  Loss: 0.12296199798583984  Accuracy: 96.27380952380952 %\n",
      "Iteration: 7500  Loss: 0.10664860904216766  Accuracy: 96.11904761904762 %\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train  = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0e527a85-b600-4e40-a0ef-850537db2ab1",
    "_uuid": "0cb7130ea6e22093d6d5cb1284822b0b76b8d66c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-87df09b54343>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualization loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of iteration\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RNN: Loss vs Number of iteration\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eeaf09ff-e125-42ee-99fa-e231e97c4308",
    "_uuid": "0771ccf728b05cf6a5e3804e7d9bc5fa376e7ef8"
   },
   "source": [
    "### Conclusion\n",
    "In this tutorial, we learn: \n",
    "1. Basics of pytorch\n",
    "1. Linear regression with pytorch\n",
    "1. Logistic regression with pytorch\n",
    "1. Artificial neural network with with pytorch\n",
    "\n",
    "\n",
    "<br> If you have any question or suggest, I will be happy to hear it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
